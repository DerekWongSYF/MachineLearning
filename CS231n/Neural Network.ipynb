{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmod(x, derive=False):\n",
    "    if (derive == True):\n",
    "        return x * (1 - x)\n",
    "    return 1 / (1 + np.exp(-x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[0, 0, 1],\n",
    "              [0, 1, 1],\n",
    "              [1, 0, 1],\n",
    "              [1, 1, 1],\n",
    "              [0, 0, 1]])\n",
    "x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([[0], [1], [1], [0], [0]])\n",
    "y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error:0.4918739397364801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error:0.009794284463972344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error:0.006493076538438727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error:0.005144157678376962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error:0.00437274918169706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error:0.0038603867449685135\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "w0 = 2 * np.random.random((3, 4)) - 1\n",
    "w1 = 2 * np.random.random((4, 1)) - 1\n",
    "w0, w1\n",
    "for j in range(60000):\n",
    "    l0 = x\n",
    "    l1 = sigmod(np.dot(l0, w0))\n",
    "    l2 = sigmod(np.dot(l1, w1))\n",
    "    l2_error = y - l2\n",
    "    if (j % 10000 == 0):\n",
    "        print(\"error:\" + str(np.mean(np.abs(l2_error))))\n",
    "    l2_delta = l2_error * sigmod(l2, derive=True)\n",
    "    l1_error = l2_delta.dot(w1.T)\n",
    "    l1_delta = l1_error * sigmod(l1, derive=True)\n",
    "    w1 += (l1.T).dot(l2_delta)\n",
    "    w0 += (l0.T).dot(l1_delta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, num_classes,\n",
    "                 input_size, hidden_size,\n",
    "                 reg=1e-5,\n",
    "                 learning_rate=1e-4,\n",
    "                 batch=1000):\n",
    "        self.num_classes = num_classes\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.reg = reg\n",
    "        self.batch = batch\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def initialize(self):\n",
    "        self.w0 = 1e-3 * np.random.randn(self.input_size, self.hidden_size)\n",
    "        self.w1 = 1e-3 * np.random.randn(self.hidden_size, self.num_classes)\n",
    "\n",
    "    def relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def front_propagation(self, x, w):\n",
    "        score = x.dot(w)\n",
    "        return score\n",
    "\n",
    "    def softmax(self, x, y, w0, w1):\n",
    "        n = x.shape[0]\n",
    "        correct_classes = x[range(x.shape[0]), list(y)].reshape(-1, 1)\n",
    "        exp_sum = np.sum(np.exp(x), axis=1).reshape(-1, 1)\n",
    "        loss = np.sum(np.log(exp_sum) - correct_classes)\n",
    "        loss = loss / n + \\\n",
    "               0.5 * self.reg * np.sum(w0 ** 2) + \\\n",
    "               0.5 * self.reg * np.sum(w1 ** 2)\n",
    "\n",
    "        dw = np.exp(x) / exp_sum\n",
    "        dw[range(n), list(y)] -= 1\n",
    "        dw /= n\n",
    "        return loss, dw\n",
    "\n",
    "    def relu_backpropagation(self, dout, x):\n",
    "        dx = dout\n",
    "        dx[x <= 0] = 0\n",
    "        return dx\n",
    "\n",
    "    def backpropagation(self, x, w, dout):\n",
    "        dx = dout.dot(w.T)\n",
    "        dw = x.T.dot(dout)\n",
    "        return dx, dw\n",
    "\n",
    "    def ready_for_data(self, x, y):\n",
    "        training_x_list = []\n",
    "        training_y_list = []\n",
    "        start = 0\n",
    "        num_train = x.shape[0]\n",
    "        n = int(num_train / self.batch)\n",
    "        for i in range(n):\n",
    "            singleX = x[start:start + self.batch, :]\n",
    "            singleY = y[start:start + self.batch]\n",
    "            start += self.batch\n",
    "            training_x_list.append(singleX)\n",
    "            training_y_list.append(singleY)\n",
    "        return training_x_list, training_y_list, n\n",
    "\n",
    "    def pridict(self, x, y):\n",
    "        score = x.dot(self.w0)\n",
    "        score = self.relu(score)\n",
    "        score = score.dot(self.w1)\n",
    "        ypredict = np.argmax(score, axis=1)\n",
    "        acc = np.mean(ypredict == y)\n",
    "        return acc\n",
    "\n",
    "    def training(self, x, y, time=50):\n",
    "        for i in range(time):\n",
    "            l0 = x\n",
    "            l1 = self.front_propagation(l0, self.w0)\n",
    "            l1_relu = self.relu(l1)\n",
    "            l2 = self.front_propagation(l1_relu, self.w1)\n",
    "            loss, dout = self.softmax(l2, y, self.w0, self.w1)\n",
    "\n",
    "            if (i == time - 1):\n",
    "                for k in range(int(time / 100)):\n",
    "                    print(\"=\", end=\"=\")\n",
    "                    pass\n",
    "                print(\"| 100.0%\")\n",
    "\n",
    "            if (i % 100 == 0):\n",
    "                print(\"loss : {:.6f}\".format(loss))\n",
    "                for k in range(int(i / 100)):\n",
    "                    print(\"=\", end=\"=\")\n",
    "                    pass\n",
    "                print(\" \", (i / time) * 100, \"%\")\n",
    "\n",
    "            dout, dw1 = self.backpropagation(l1_relu, self.w1, dout)\n",
    "\n",
    "            dout = self.relu_backpropagation(dout, l1)\n",
    "\n",
    "            dout, dw0 = self.backpropagation(l0, self.w0, dout)\n",
    "\n",
    "            dw0 += self.reg * self.w0\n",
    "            dw1 += self.reg * self.w1\n",
    "\n",
    "            self.w0 -= self.learning_rate * dw0\n",
    "            self.w1 -= self.learning_rate * dw1\n",
    "\n",
    "            pass\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assignment1-two layer network\n",
    "import pickle\n",
    "\n",
    "def getDate(file):\n",
    "    with open(file, 'rb') as fileOpen:\n",
    "        dict = pickle.load(fileOpen, encoding=\"bytes\")\n",
    "    return dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1 = getDate(\"CS231n/cifar-10-batches-py/data_batch_1\")\n",
    "dict2 = getDate(\"CS231n/cifar-10-batches-py/data_batch_2\")\n",
    "dict3 = getDate(\"CS231n/cifar-10-batches-py/data_batch_3\")\n",
    "dict4 = getDate(\"CS231n/cifar-10-batches-py/data_batch_4\")\n",
    "dict5 = getDate(\"CS231n/cifar-10-batches-py/data_batch_5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第3组数据 : \n初始化weight\n第1个batch : \nloss : 2.308416\n  0.0 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accruacy :  0.1474\n第2个batch : \nloss : 2.261027\n  0.0 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accruacy :  0.1997\n第3个batch : \nloss : 2.185547\n  0.0 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accruacy :  0.2487\n第4个batch : \nloss : 2.074975\n  0.0 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accruacy :  0.267\n第5个batch : \nloss : 2.029452\n  0.0 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accruacy :  0.2756\n第6个batch : \nloss : 1.972757\n  0.0 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accruacy :  0.2919\n第7个batch : \nloss : 1.945130\n  0.0 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accruacy :  0.302\n第8个batch : \nloss : 1.954174\n  0.0 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accruacy :  0.3083\n第9个batch : \nloss : 1.911614\n  0.0 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accruacy :  0.31\n第10个batch : \nloss : 1.892885\n  0.0 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accruacy :  0.3278\n第3组数据 : \n第1个batch : \nloss : 1.864883\n  0.0 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accruacy :  0.3413\n第2个batch : \nloss : 1.862158\n  0.0 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accruacy :  0.3475\n第3个batch : \nloss : 1.851304\n  0.0 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-ee7184f20c14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mtrainY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mb'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"第3组数据 : \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mrun_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mb'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mb'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-ee7184f20c14>\u001b[0m in \u001b[0;36mrun_batch\u001b[0;34m(trainX, trainY, testX, testY, classifier, init)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"第{0}个batch : \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"accruacy : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpridict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-23eac9302d71>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(self, x, y, time)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0ml0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0ml1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfront_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0ml1_relu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0ml2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfront_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml1_relu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-23eac9302d71>\u001b[0m in \u001b[0;36mfront_propagation\u001b[0;34m(self, x, w)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfront_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "def run_batch(trainX, trainY, testX, testY, classifier, init=False):\n",
    "    if (init == True):\n",
    "        print(\"初始化weight\")\n",
    "        classifier.initialize()\n",
    "    train_X, train_Y, n = classifier.ready_for_data(trainX, trainY)\n",
    "    for i in range(n):\n",
    "        print(\"第{0}个batch : \".format(i + 1))\n",
    "        classifier.training(train_X[i], train_Y[i])\n",
    "        print(\"accruacy : \", classifier.pridict(testX, testY))\n",
    "\n",
    "classifier = NeuralNetwork(10, 3 * 32 * 32, 128)\n",
    "trainX = dict1[b'data']\n",
    "trainY = dict1[b'labels']\n",
    "print(\"第1组数据 : \")\n",
    "run_batch(trainX, trainY, dict2[b'data'], dict2[b'labels'], classifier, init=True)\n",
    "\n",
    "trainX = dict2[b'data']\n",
    "trainY = dict2[b'labels']\n",
    "print(\"第2组数据 : \")\n",
    "run_batch(trainX, trainY, dict1[b'data'], dict1[b'labels'], classifier)\n",
    "\n",
    "trainX = dict3[b'data']\n",
    "trainY = dict3[b'labels']\n",
    "print(\"第3组数据 : \")\n",
    "run_batch(trainX, trainY, dict2[b'data'], dict2[b'labels'], classifier)\n",
    "\n",
    "trainX = dict4[b'data']\n",
    "trainY = dict4[b'labels']\n",
    "print(\"第4组数据 : \")\n",
    "run_batch(trainX, trainY, dict3[b'data'], dict3[b'labels'], classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.391"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.pridict(dict1[b'data'], dict1[b'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
